{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Link Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Q1:\n",
    "Compute the Topic-Specific PageRank for the following link topology.\n",
    "\n",
    "* Assume that pages selected for the teleport set are nodes 1 and 2 and that in the teleport set, the weight assigned for node 1 is twice that of node 2.\n",
    "* Assume further that the teleport probability, (1 - beta), is 0.3.\n",
    "\n",
    "Which of the following statements is correct?\n",
    "\n",
    "* TSPR(2) = .2252\n",
    "* TSPR(2) = .8998\n",
    "* TSPR(3) = .1092\n",
    "* TSPR(4) = .4787\n",
    "\n",
    "![ala1](ALA1.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We redistribute the missing page rank to the rows of the teleport set!\n",
      "[[1.33333333 1.33333333 1.33333333 1.33333333]\n",
      " [0.66666667 0.66666667 0.66666667 0.66666667]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]]\n",
      "[[0.2  0.9  0.2  0.2 ]\n",
      " [0.45 0.1  0.1  0.1 ]\n",
      " [0.35 0.   0.   0.7 ]\n",
      " [0.   0.   0.7  0.  ]]\n",
      "3.9999999999999996\n"
     ]
    }
   ],
   "source": [
    "beta= 0.7\n",
    "nodes = 4\n",
    "teleportSet = 2\n",
    "M = np.matrix([ [0,   1., 0,  0]\n",
    "               ,[0.5, 0,  0,  0]\n",
    "               ,[0.5, 0,  0,  1.]\n",
    "               ,[0,   0,  1., 0]])\n",
    "#print M\n",
    "f = np.matrix([4./3., 2./3.,0,0])\n",
    "e = np.matrix(np.repeat(1, nodes))\n",
    "print \"We redistribute the missing page rank to the rows of the teleport set!\"\n",
    "print np.multiply(e, f.T)\n",
    "formula = beta*M+(1-beta)*(1./teleportSet)*np.multiply(e, f.T)\n",
    "print formula\n",
    "print np.sum(formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.375  0.1875 0.2625 0.175 ]]\n",
      "[[0.33125 0.23125 0.25375 0.18375]]\n",
      "[[0.361875  0.2159375 0.2445625 0.177625 ]]\n",
      "[[0.35115625 0.22665625 0.25099375 0.17119375]]\n",
      "[[0.35865938 0.22290469 0.24274031 0.17569562]]\n",
      "[[0.35603328 0.22553078 0.24851772 0.16991822]]\n",
      "[[0.35787155 0.22461165 0.2435544  0.1739624 ]]\n",
      "[[0.35722815 0.22525504 0.24702872 0.17048808]]\n",
      "[[0.35767853 0.22502985 0.24437151 0.17292011]]\n",
      "[[0.3575209  0.22518749 0.24623156 0.17106006]]\n",
      "[[0.3575209  0.22518749 0.24623156 0.17106006]]\n"
     ]
    }
   ],
   "source": [
    "r = np.matrix([0.25, 0.25, 0.25, 0.25]).T\n",
    "\n",
    "for _ in range(10):\n",
    "    r = np.dot(formula,r)/np.sum(np.dot(formula,r))\n",
    "    print r.T\n",
    "    \n",
    "print r.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Q2:\n",
    "\n",
    "![ala2](ALA2.gif)\n",
    "\n",
    "$x$ = outside contribution page rank\n",
    "\n",
    "$n$ = total number of pages in the web\n",
    "\n",
    "page rank of $k$ second tier pages = $\\beta \\frac{y}{k} + \\frac{(1-\\beta)}{n} = w$\n",
    "\n",
    "page rank of $m$ supporters = $\\beta w + \\frac{(1-\\beta)}{n}$\n",
    "\n",
    "Thus the page rank $y$ of the page t is:\n",
    "\n",
    "$$y = x + \\beta m \\left(\\beta w + \\frac{(1-\\beta)}{n}\\right) + \\frac{(1-\\beta)}{n}$$\n",
    "or, outside contribution, plus $\\beta$ the page rank of the in-linking pages plus the random teleport stuff.\n",
    "\n",
    "Rearranging we get:\n",
    "\n",
    "$$y = \\frac{x}{(1 - \\beta^3)} + \\frac{k(1-\\beta)}{n(1-\\beta^3)}+ \\frac{m (1-\\beta)}{n (1-\\beta^3)} + \\frac{1-\\beta}{n(1-\\beta^3)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.59151279559\n",
      "0.330417881438\n",
      "0.388726919339\n"
     ]
    }
   ],
   "source": [
    "a = lambda x: 1./(1-x**3)\n",
    "b = lambda x: x*(1.-x)*a(x)\n",
    "c = lambda x: b(x)/x\n",
    "\n",
    "print a(0.85)\n",
    "print b(0.85)\n",
    "print c(0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Q1:\n",
    "Suppose we have an LSH family h of (d1,d2,.6,.4) hash functions. We can use three functions from h and the AND-construction to form a (d1,d2,w,x) family, and we can use two functions from h and the OR-construction to form a (d1,d2,y,z) family. Calculate w, x, y, and z, and then identify the correct value of one of these in the list below:\n",
    "\n",
    "* z=.64\n",
    "* z=.16\n",
    "* y=.936\n",
    "* z=.784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w 0.216 x 0.064 y 0.84 z 0.64\n"
     ]
    }
   ],
   "source": [
    "# (d1,d2,.6,.4) implies will pair up if distance <=d1 with probability >= 0.6\n",
    "# and if distance >=d2 then the probability of pairing is <= 0.4\n",
    "\n",
    "# AND construction\n",
    "# we raise to the power 3 since there are 3 has functions\n",
    "w = 0.6**3\n",
    "x = 0.4**3\n",
    "\n",
    "# OR construction\n",
    "y = 1 - (1 - 0.6)**2\n",
    "z = 1 - (1 - 0.4)**2\n",
    "print \"w\", w, \"x\", x, \"y\", y, \"z\", z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Q2:\n",
    "* s1 = abcef\n",
    "* s2 = acdeg\n",
    "* s3 = bcdefg\n",
    "* s4 = adfg\n",
    "* s5 = bcdfgh\n",
    "* s6 = bceg\n",
    "* s7 = cdfg\n",
    "* s8 = abcd\n",
    "\n",
    "Suppose our upper limit on Jaccard distance is 0.2, and we use the indexing scheme of Section 3.9.4 based on symbols appearing in the prefix (no position or length information). For each of s1, s3, and s6, determine how many other strings that string will be compared with, if it is used as the probe string. Then, identify the true count from the list below.\n",
    "\n",
    "* s3 is compared with 2 other strings.\n",
    "* s3 is compared with 5 other strings.\n",
    "* s1 is compared with 3 other strings.\n",
    "* s3 is compared with 4 other strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String 1 indexed on the first 2 symbols\n",
      "String 2 indexed on the first 2 symbols\n",
      "String 3 indexed on the first 2 symbols\n",
      "String 4 indexed on the first 1 symbols\n",
      "String 5 indexed on the first 2 symbols\n",
      "String 6 indexed on the first 1 symbols\n",
      "String 7 indexed on the first 1 symbols\n",
      "String 8 indexed on the first 1 symbols\n",
      "a [1, 2, 4, 8]\n",
      "c [2, 3, 5, 7]\n",
      "b [1, 3, 5, 6]\n",
      "e []\n",
      "d []\n",
      "g []\n",
      "f []\n",
      "h []\n"
     ]
    }
   ],
   "source": [
    "stringInfo= [(1, 5),(2, 5),(3,6),(4,4),(5,6),(6,4),(7,4),(8,4)]\n",
    "strings= [\"abcef\", \"acdeg\", \"bcdefg\", \"adfg\", \"bcdfgh\", \"bceg\", \"cdfg\", \"abcd\"]\n",
    "\n",
    "d = dict(zip(\"abcdefgh\", [[] for _ in xrange(8)]))\n",
    "j = 0.2\n",
    "for (name, length), s in zip(stringInfo, strings):\n",
    "    p = int(j*length) + 1\n",
    "    for char in strings[name - 1][:p]:\n",
    "        d[char].append(name)\n",
    "    print \"String {} indexed on the first {} symbols\".format(name, p)\n",
    "    \n",
    "for key, value in d.iteritems():\n",
    "    print key, value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Q3:\n",
    "Construct the link graph for the following graph:\n",
    "\n",
    "![ala3](ALA3.gif)\n",
    "\n",
    "First, construct the L, the link matrix, as discussed in Section 5.5 on the HITS algorithm. Then do the following:\n",
    "\n",
    "* Start by assuming the hubbiness of each node is 1; that is, the vector h is (the transpose of) [1,1,1,1].\n",
    "* Compute an estimate of the authority vector a=LTh.\n",
    "* Normalize a by dividing all values so the largest value is 1.\n",
    "* Compute an estimate of the hubbiness vector h=La.\n",
    "* Normalize h by dividing all values so the largest value is 1.\n",
    "* Repeat steps 2-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** 0\n",
      "hubs [[1.    0.333 0.333 0.667]]\n",
      "authorities [[0.5 0.5 1.  0.5]]\n",
      "***** 1\n",
      "hubs [[1.    0.125 0.125 0.625]]\n",
      "authorities [[0.2 0.6 1.  0.2]]\n"
     ]
    }
   ],
   "source": [
    "L =np.matrix([[0,1,1,0]\n",
    "              ,[1,0,0,0]\n",
    "              ,[0,0,0,1]\n",
    "              ,[0,0,1,0]])\n",
    "\n",
    "h = np.matrix([1.,1.,1.,1.]).T\n",
    "\n",
    "for _ in xrange(2):\n",
    "    a = np.dot(L.T, h)\n",
    "    a = a/np.max(a)\n",
    "    h = np.dot(L, a)\n",
    "    h = h/np.max(h)\n",
    "    print \"*\" * 5, _\n",
    "    print \"hubs\", np.round(h.T, decimals=3) \n",
    "    print \"authorities\", np.round(a.T, decimals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Q4:\n",
    "Consider an implementation of the Block-Stripe Algorithm discussed in Section 5.2 to compute page rank on a graph of N nodes (i.e., Web pages). Suppose each page has, on average, 20 links, and we divide the new rank vector into k blocks (and correspondingly, the matrix M into k stripes). Each stripe of M has one line per \"source\" web page, in the format:\n",
    "\n",
    "[source_id, degree, m, dest_1, ...., dest_m]\n",
    "\n",
    "Notice that we had to add an additional entry, m, to denote the number of destination nodes in this stripe, which of course is no more than the degree of the node. Assume that all entries (scores, degrees, identifiers,...) are encoded using 4 bytes.\n",
    "\n",
    "There is an additional detail we need to account for, namely, locality of links. As a very simple model, assume that we divide web pages into two disjoint sets:\n",
    "\n",
    "* Introvert pages, which link only to other pages within the same host (block) as themselves.\n",
    "* Extrovert pages, which have links to pages across several hosts.\n",
    "\n",
    "Assume a fraction x of pages are introverts, and the rest are extroverts. Construct a formula that counts the amount of I/O per page rank iteration in terms of N, x, and k. The 4-tuples below list combinations of N, k, x, and I/O (in bytes). Pick the correct combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120.0 132 12.0\n",
      "120.0 120 0.0\n",
      "110.0 116 6.0\n",
      "110.0 112 2.0\n"
     ]
    }
   ],
   "source": [
    "data = [(10**9, 3, 0.5, 132),(10**9, 3, 0.5, 120),(10**9, 2, 0.5, 116),(10**9, 2, 0.5, 112)]\n",
    "\n",
    "def cost(N, k, x):\n",
    "    return 4*((k+1)*N + 23*x*N + (3*k + 20)*(1-x)*N)/(1.*N)\n",
    "\n",
    "for N, k, x, answer in data:\n",
    "    print cost(N,k,x), answer, answer - cost(N,k,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of bytes involved in reading the old pagerank vector and writing the new pagerank vector to disk = 4 (k+1) N\n",
    "\n",
    "For the M matrix:\n",
    "\n",
    "* The introvert pages will appear xN times and each row will have on average 23 entries (3 metadata and 20 destination links).\n",
    "    * Total number of bytes read = 4*23 xN\n",
    "    * These pages occur in only one block since they link only to other pages in the same block as themselves (hence x*N rows)~\n",
    "* The extrovert pages will appear (1-x) kN times and each row will have 3 (metadata) + 20/k (destination links) entries on average\n",
    "    * Total number of bytes read = 4 (3+20/k) (1-x) kN\n",
    "    * Extrovert pages will occur in (possibly) all blocks, since they can link to any other page. Thereare(1-x)*N such pages and k blocks, hence the end factor. There are 20 links, spread between the k blocks, hence the 3 + 20/k pages linked to within each block\n",
    "* Total I/O per pagerank iteration (in GB, where 1GB ~ 10^9 = N bytes) = 4 [(k+1) N + 23 xN + (3k + 20) (1-x) N] / N = 4 [(k+1) + 23 x + (3k + 20) (1-x)] = 4 [21 + k + 3 (x + (1-x) k)]\n",
    "* Factor of N to get in terms of gigabytes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
